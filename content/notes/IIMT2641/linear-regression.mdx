---
title: Linear Regression
---

## Single variable linear regression

!!! tip "Dependent and independent variables"

    - **Dependent variable**: The variable we are trying to predict (y)
    - **Independent variable**: The variable we are using to make predictions (x)

!!! tip "Simple regression model"

    The population model of y with one **independent** variable x is given by:

    ```math
    y = \beta_0 + \beta_1 x
    ```

    where:
    - $\beta_0$ is the y-intercept
    - $\beta_1$ is the slope

    we can express the model as a regression function:

    ```math
    E[y|x] = \beta_0 + \beta_1 x
    ```

    where $E[y|x]$ is the expected value of y given x. From the *straight-line* formula, $\beta_0$ is the y-intercept and $\beta_1$ is the slope of the line.

!!! tip "Estimated regression function"

    Estimates the regression model with n observations (x_i, y_i)

    ```math
    \hat{y} = \hat{\beta_0} + \hat{\beta_1} x
    ```

    where:
    - $\hat{\beta_0}$ is the estimated y-intercept
    - $\hat{\beta_1}$ is the estimated slope

!!! info "Residuals"

    The difference between the observed value of the dependent variable and the predicted value.

    ```math
    e_i = y_i - \hat{y_i}
    ```

!!! note "Sum of Squared Errors (SSE)"

    ```math
    SSE = \sum_{i=1}^{n} (y_i - \hat{y_i})^2
    ```

!!! note "Total Sum of Squares (SST)"

    ```math
    SST = \sum_{i=1}^{n} (\hat{y_i} - \bar{y})^2
    ```

    where:
    - $\bar{y}$ is the mean of the dependent variable

!!! tip "Coefficient of Determination (R square)"

    The coefficient of determination $R^2$, ranged from $0\to1$ is a measure of **how well the model fits the data**.

    ```math
    R^2 = 1 - \frac{SSE}{SST}
    ```

    where:
    - SSR is the sum of squared residuals
    - SST is the total sum of squares

## Multi-variable linear regression

!!! tip "Multiple regression model"

    The population model of y with k independent variables is given by:

    ```math
    y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k
    ```

    where:
    - $y$ is the dependent variable
    - $x_1, x_2, ..., x_k$ are the independent variables
    - $\beta_0$ is the y-intercept
    - $\beta_1, \beta_2, ..., \beta_k$ are the slopes

!!! note "Multicollinearity"

    We would want IVs to be uncorrelated with each other, but in the real world, they are often **collinear**. If the correlations are too large, then estimated coefficients will be **unreliable**. This is called **multicollinearity**.

!!! info "Variance inflation factors"

    Checks for multicollinearity, of an IV. Use `vif(model)`. If value $< 10$ no problem, else drop variable.

!!! info "Adjusted R square"

    Modified version of $R^2$ that adjusts for the number of IVs. (Produced in `summary(model)`)

## Making predictions

!!! info "In-sample and out-of-sample R square"

    - **In-sample R square**: The proportion of variance explained by the model on the training data.
    - **Out-of-sample R square**: The proportion of variance explained by the model on the test data. The value can be negative, indicating that the model is worse than a simple mean prediction.

## Difference in differences

Correlation does not mean causation. We use DiD to estimate the **casual effect** (causation) from a **treatment** (intervention), estimated by:

```math
DiD = \Delta {T} - \Delta {C}
```

T is the treatment group and C is the control group. 

!!! tip "DiD by linear regression"

    Using linear regression:

    ```math
    y = \beta_0 + \beta_1 T + \beta_2 P + \beta_3 (T * P)
    ```

    where:
    - $T$ is the treatment group (1 if treated, 0 if not)
    - $P$ is the post-treatment period (1 if post, 0 if pre)
    - $T * P$ is the interaction term (1 if treated AND post, 0 otherwise)

    - $\beta_0 = E[y | T=0, P=0]$ (control group pre-treatment)
    - $\beta_1 = E[y | T=1, P=0] - E[y | T=0, P=0]$ (treatment group pre-treatment)
    - $\beta_2 = E[y | T=0, P=1] - E[y | T=0, P=0]$ (control group post-treatment)
    - $\beta_3 = E[y | T=1, P=1] - E[y | T=0, P=1] - E[y | T=1, P=0] + E[y | T=0, P=0]$ (DiD)

!!! note "Estimate DiD using R-lang"

    pass

!!! info "Requirements for DiDs"

    1. Both "pre" and "post" periods must be observed for both treatment and control groups.
    2. Must have control and treated group, where the control should exhibit **parallel trend** before treatment

## Conducting analysis with R-lang

<Steps>

### Load and Explore the Dataset
Understand the structure of the dataset and identify potential predictors and target variables.

#### R Commands:
```r
# Load the dataset
data <- read.csv("your_dataset.csv")

# Check the structure and summary of the data
str(data)
summary(data)

# Check for missing values
sum(is.na(data))

# View the first few rows
head(data)
```

#### Metrics to Look Out For:
- **Variable Types**: Identify numerical and categorical variables.
- **Missing Values**: Assess if data cleaning is required.
- **Outliers**: Look for extreme values in numerical variables.



### Visualize Relationships Between Variables
Identify potential relationships and correlations between predictors and the target variable.

#### R Commands:
```r
# Scatter plot for numerical predictors vs target
plot(data$Predictor, data$Target, main="Scatter Plot", xlab="Predictor", ylab="Target")

# Correlation matrix for numerical variables
cor(data[, sapply(data, is.numeric)])

# Pairwise scatter plots for multiple variables
pairs(~ Predictor1 + Predictor2 + Target, data=data)

# Boxplot for categorical predictors
boxplot(Target ~ CategoricalPredictor, data=data, main="Boxplot of Target by Categorical Predictor")
```

#### Metrics to Look Out For:
- **Linear Relationships**: Check for linear trends between predictors and the target variable.
- **Correlations**: Identify variables with high correlation to the target variable.



### Prepare the Data
Clean and preprocess the dataset (e.g., handling missing values, creating new variables, or encoding categorical variables).

#### R Commands:
```r
# Handle missing values (e.g., replace with mean or remove rows)
data$Predictor[is.na(data$Predictor)] <- mean(data$Predictor, na.rm=TRUE)
data <- na.omit(data)

# Create new variables (e.g., differences, ratios, or transformations)
data$NewVariable <- data$Variable1 - data$Variable2

# Encode categorical variables (if applicable)
data$CategoricalPredictor <- as.factor(data$CategoricalPredictor)
```

#### Key Considerations:
- Handle missing values appropriately.
- Create meaningful derived features (e.g., differences, ratios).
- Ensure categorical variables are properly encoded.



### Split the Dataset
Separate the data into training and testing sets for model evaluation.

#### R Commands:
```r
# Install and load the caret package (if not already installed)
install.packages("caret")
library(caret)

# Split the data (e.g., 70% training, 30% testing)
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(data$Target, p=0.7, list=FALSE)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]
```

#### Metrics to Look Out For:
- **Balanced Splits**: Ensure the training and testing sets are representative of the overall dataset.



### Build a Linear Regression Model
Fit a linear regression model to the training data and evaluate its performance.

#### R Commands:
```r
# Fit the linear regression model
model <- lm(Target ~ Predictor1 + Predictor2 + Predictor3, data=train)

# View the summary to evaluate significance of predictors
summary(model)
```

#### Metrics to Look Out For:
- **R²**: Proportion of variance in the target variable explained by the predictors.
- **p-values**: Identify significant predictors (p-value < 0.05).
- **Coefficients**: Assess the magnitude and direction of relationships.



### Evaluate the Model
Assess the model's performance on the training data.

#### R Commands:
```r
# Predict on the training set
train_predictions <- predict(model, newdata=train)

# Compute residuals
residuals <- train$Target - train_predictions

# Compute metrics
SSE <- sum(residuals^2)
RMSE <- sqrt(SSE / nrow(train))

# Print metrics
SSE
RMSE
```

#### Metrics to Look Out For:
- **Sum of Squared Errors (SSE)**: Lower values indicate better fit.
- **Root Mean Squared Error (RMSE)**: Indicates the average error in predictions.



### Refine the Model
Simplify the model by removing insignificant predictors or multicollinear variables.

#### R Commands:
```r
# Refit the model with significant predictors
model_refined <- lm(Target ~ Predictor1 + Predictor2, data=train)

# View summary to verify improvements
summary(model_refined)
```

#### Metrics to Look Out For:
- Check for improved p-values and minimal change in RMSE or R² after removing variables.



### Test the Model on the Test Set
Evaluate the model's generalizability using out-of-sample data.

#### R Commands:
```r
# Predict on the test set
test_predictions <- predict(model_refined, newdata=test)

# Compute test SSE, RMSE, and R²
test_residuals <- test$Target - test_predictions
SSE_test <- sum(test_residuals^2)
RMSE_test <- sqrt(SSE_test / nrow(test))

SST_test <- sum((mean(train$Target) - test$Target)^2)
R2_test <- 1 - (SSE_test / SST_test)

# Print metrics
SSE_test
RMSE_test
R2_test
```

#### Metrics to Look Out For:
- **Out-of-Sample R²**: Indicates how well the model generalizes to new data.
- **RMSE**: Compare test RMSE to training RMSE to check for overfitting.



### Make Predictions
Use the model to make predictions on new data.

#### R Commands:
```r
# Predict on new data
new_predictions <- predict(model_refined, newdata=new_data)

# View predictions
new_predictions
```

</Steps>

### **Summary of Key Metrics**
1. **R²**: Indicates the proportion of variance explained by the model.
2. **p-values**: Identify statistically significant predictors.
3. **SSE**: Measures the total prediction error.
4. **RMSE**: Represents the average prediction error.
5. **Out-of-Sample R² and RMSE**: Assess generalizability.

By following these steps, you can perform a similar analysis on any dataset using R.